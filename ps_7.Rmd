---
title: 'Problem Set #7'
author: "Jack Schroeder and Oliver Cordeiro"
date: "11/15/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#We read in the necessary libraries for the problem set.
library(tidyverse)
library(dplyr)
library(knitr)
library(stringr)
library(lubridate)
library(janitor)
library(kableExtra)
library(fs)
library(foreign)

#Mr. Schroeder's dataset is read in (the file was
#downloaded and moved during class).
jack <- read_csv("jack.csv") %>% 
#We unite the state and district columns by a hyphen to
#have an output of regular district notation (ex. NJ-07).
  unite("district", c("state", "district"), sep="-")

#We downloaded the Upshot data.
download.file("https://github.com/TheUpshot/2018-live-poll-results/archive/master.zip", destfile = "upshot.zip")

#We unzipped Upshot data. 
unzip("upshot.zip")

#We deleted the zipfile.
file_delete("upshot.zip")


#We take the polldata. 
polldata <- dir_ls("2018-live-poll-results-master/data/")



#We map the data to upshot. We also separate by hyphen
#to extract district and wavenum from the file names.
upshot <- map_dfr(polldata, read_csv, .id="name") %>% 
  separate(name, c("directory","2","live","unneeded","results","poll","district","wavenum"),sep="-")%>% 
#We separate state and district. We will unite them later
#after adding a hyphen.
  separate(district,c("state","district"),sep=2) %>% 
#We separate wavenum to get rid of the ".csv" portion.
  separate(wavenum,c("wave","csv"),sep=1) %>% 
#We unselect the unnecessary variables.
  select(-directory, -`2`,-live,-unneeded,-results,-poll,-csv)

#We make the state abbreviations uppercase.
upshot$state <- str_to_upper(upshot$state)

#Now we can unite state and district to make a uniform
#district column.
upshot <- upshot %>% 
  unite("district", c("state", "district"), sep="-")

#We left_join upshot and jack to add the actual results
#to the poll data.
joined <- left_join(upshot, jack)

#We want to examine whether districts with a larger
#proportion of outliers were more unreliable in predicting
#vote totals. To do this, we group final_weights into
#categories. We treat a final_weight below 0.5 and above
#1.5 as an outlier.
join1 <- joined %>% 
#This is achieved using a case_when.
  mutate(grouped_final_weight = case_when(final_weight <= 1.5 ~ "Normal",
                                          final_weight > 1.5  ~ "Outlier")) %>% 
#We then group_by district and our new variable.
  group_by(district,grouped_final_weight) %>% 
#Counting prepares us for the spread.
  count() %>% 
#Spreading by the new variable to generate totals in
#each district polled. It is worth noting here that wave
#is not important. We just want to know the total
#proportion of outliers. As a result, districts polled
#twice are not treated any differently.
  spread(key=grouped_final_weight, value=n) %>% 
#We create a total of normal and outlier results, and then
#divide the number of outliers by this number to get our
#outlier percentage.
  mutate(total = Normal + Outlier, outlier_per = Outlier/total)

#We then left_join these results with our previously
#joined data to create newdata.
newdata <- left_join(joined, join1)

#An inner_join of the results and the outlier table gives
#us almost everything we need. We just need to add the
#forecasted vote percentages.
newdata2 <- inner_join(jack, join1) %>% 
  arrange(desc(outlier_per))

#We then find the forecasted vote percentages. This starts by using our joined dataset
join2 <- upshot %>% 
#We first group_by state, district, wave, and response. This is similar to the midterm.
  group_by(district,wave,response) %>% 
#We need to tally by final_weight to get The Upshot's weighted predictions.
  tally(wt=final_weight)%>% 
#We use a case_when to sum up each response in a total column.
  mutate(total=case_when(response%in%c("Dem", "Rep","Und","3","4","5","6") ~ sum(n))) %>%
#We spread using response as a key and the n from tally as a value.
  spread(key=response, value=n)%>% 
#Then we can create Democratic Advantage (since we're seeing what factors caused The
#Upshot to over/underexaggerate the blue wave!). This initial advantage is Dem-Rep.
  mutate(initialad = Dem-Rep) %>% 
#We then divide this number by the total to get our real Democratic Advantage.
  mutate(dem_advantage_forecast = initialad/total) %>% 
  #I select the necessary columns.
  select(district,wave,dem_advantage_forecast) %>% 
#We still have some work to do because some districts were polled twice. Unlike with the
#outliers above, we only want the forecasted democratic advantage from the latest poll
#in each district.
    spread(key=wave,value=dem_advantage_forecast)

#NA values have to be 0 for the following code to work.
join2[is.na(join2)] <- 0

#Returning to the upshot data that will be joined: two case_whens should do the trick. This is the code
#Mr. Schroeder used on the midterm.
join2 <- join2 %>% 
#The first casewhen tells R to make the value of our new column the third wave value if
#it is not equal to 0 (that is, not a 0 value created by our NA code above). If it is equal
#to 0, it should take the sum of waves 1 and 2, which, because I have made NA values 0, should
#take districts not polled in the third wave and set the new column equal to the Democratic advantage
#in whichever wave it was actually polled in.
  mutate(demadforecastfake = case_when(3 == 0.0000000000 ~ (`1` + `2`),
                                       3 != 0.0000000000 ~ `3`)) %>% 
#That code worked for the non-NA values, but not the NA values I made equal to 0. Surprisingly,
#the following code finishes the job. By making a new Democratic advantage column (this one also
#called dem_advantage_forecast), I make it the sum of waves 1 and 2 if the column I just created is equal
#to 0, and equal to the above column if it has a value. In other words, the final result is the
#Democratic advantage of the last polling of each district.
  mutate(dem_advantage_forecast = case_when(demadforecastfake == 0.0000000000 ~ (`1` + `2`),
                                   TRUE ~ demadforecastfake)) %>% 
#I only want district and dem_advantage_forecast moving forward.
  select(district,dem_advantage_forecast)

#We then join this to newdata2 to create newdata3, which is newdata2 with the forecasted
#percent margins added.
newdata3 <- left_join(newdata2, join2) %>% 
  select(district, win_name, win_party, dem_votes, rep_votes, other_votes, Normal, Outlier, total, outlier_per, dem_advantage_forecast) %>% 
#Three mutates create total votes, initial Democratic advantage, and real Democratic advantage for our
#district-by-district results.
  mutate(totalvotes = dem_votes + rep_votes + other_votes, initialad = dem_votes - rep_votes, dem_advantage_real = initialad/totalvotes) %>% 
#Then we select out the variables we do not need.
  select(-dem_votes, -rep_votes, -other_votes, -Normal, -Outlier, -total, -totalvotes, -initialad) %>% 
#Now, we subtract the Democratic advantages to get our margin of error.
  mutate(margin_of_error = dem_advantage_real - dem_advantage_forecast) %>% 
#We now arrange by margin of error in descending order.
  arrange(desc(margin_of_error)) %>% 
#We no longer need the individual Democratic advantages.
  select(-dem_advantage_real, -dem_advantage_forecast)

#All NA values have to be 0 for the correlation to work.
newdata3[is.na(newdata3)] <- 0

#We add a correlation column to calculate overall correlation between margin of error and percentage of 
#outliers.
newdata3 <- newdata3 %>% 
  mutate(correlation = cor(margin_of_error, outlier_per))

#We read in the data I used in the midterm of districts that flipped. We updated it (along with the results
#data) for races that have been called in the last week or so.
flip <- read_csv("flipdatabase.csv")

#We join the two datasets together to get our final dataset.
final_data <- left_join(newdata3, flip)

#Finally, we write the rds file that allows us to use this data in the app.
write_rds(final_data,"ps_7/ps7.rds",compress="none")

#We used this code to calculate correlations. It is not needed,
#so we commented it out.
final_data %>% 
  filter(win_party == "R", flip == "Hold") %>% 
  mutate(correlation2 = cor(margin_of_error, outlier_per))
```